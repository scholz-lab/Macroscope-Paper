{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c4fbc-9eda-4ed3-8312-dbb0e6fe2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import pims\n",
    "from pathlib import Path\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.io import imsave\n",
    "from skimage.measure import regionprops\n",
    "import trackpy as tp\n",
    "from scipy.signal import spectrogram, periodogram,savgol_filter\n",
    "from scipy.signal import find_peaks\n",
    "import pg_analysis.plotter as pga\n",
    "import pg_analysis\n",
    "from scipy.stats import skew\n",
    "from scipy.signal import find_peaks\n",
    "import re\n",
    "from pg_analysis import style\n",
    "#plt.style.use('~/Code/AnalysisNotebooksMKS/NIFStyle.mplstyle')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=plt.get_cmap('tab10').colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e5854-5bb7-4494-bf68-d3dd42d98bb9",
   "metadata": {},
   "source": [
    "# This script is for P. Pacificus and C.elegans predatory recordings using the dual view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1d385-674c-472b-8d87-62283761a299",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54364a-1b32-4dd6-a7b0-2a74853992b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_orientation(centerline):\n",
    "    \"\"\" Get all images into the same orientation by comparing to a sample image.\"\"\"\n",
    "    sample = centerline[0]\n",
    "    similarity = np.zeros(len(centerline))\n",
    "    for idx, cl in enumerate(centerline):\n",
    "        current = cl\n",
    "        sim = np.sum((current-sample)**2)<\\\n",
    "            np.sum((current-sample[::-1])**2)\n",
    "        similarity[idx] = sim\n",
    "        if sim:\n",
    "            sample = current\n",
    "        else:\n",
    "            sample = current[::-1]\n",
    "    print(f'Flipping {np.sum(similarity)} centerlines.')\n",
    "    tmp = []\n",
    "    for idx, entry in enumerate(similarity):\n",
    "        if entry:\n",
    "            tmp.append(centerline[idx])\n",
    "        else:\n",
    "            tmp.append(centerline[idx][:,::-1])\n",
    "    return np.array(tmp)\n",
    "\n",
    "def chunk_mean(tmp, tau, time_coordinate='frame'):\n",
    "    \"\"\"coarse-grain data and average over chunks\"\"\"\n",
    "    t_bins = np.arange(tmp[time_coordinate].min(), tmp[time_coordinate].max(), tau+1)\n",
    "    _t = np.digitize(tmp[time_coordinate], t_bins)\n",
    "    return tmp.groupby(_t).mean()\n",
    "\n",
    "# time pumping\n",
    "def percent_pump(pumprate, threshold):\n",
    "    return np.mean(pumprate>threshold)\n",
    "\n",
    "def state_durations(bin_series):\n",
    "    '''expects a binary/0-1 time series and will return the length of repeated segments.'''\n",
    "    states = {0:[], 1:[]}\n",
    "    for k, g in itertools.groupby(bin_series, key=None):\n",
    "        states[k].append(len(list(g)))\n",
    "        \n",
    "    return states\n",
    "\n",
    "def add_cbar(ax, im, label=''):\n",
    "    cax = fig.add_axes([ax.get_position().x1+0.02,ax.get_position().y0,0.02,ax.get_position().height])\n",
    "    plt.colorbar(im, cax=cax, label = label)\n",
    "    \n",
    "def align_image_orientation(centerline): \n",
    "    \"\"\" Get all images into the same orientation by comparing to a sample image.\"\"\"\n",
    "    sample = centerline[0]\n",
    "    similarity = np.zeros(len(centerline))\n",
    "    cl_flipped = []\n",
    "    for idx, cl in enumerate(centerline):\n",
    "        cl_flipped.append(sample)\n",
    "        current = cl\n",
    "        sim = np.sum((current-sample)**2) < np.sum((current-sample[::-1])**2)\n",
    "        similarity[idx] = sim\n",
    "        if sim:\n",
    "            sample = current\n",
    "        else:\n",
    "            sample = current[::-1]\n",
    "    return cl_flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42ca7a-a942-42be-97c4-12c8b31f4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = {'x': 'cm',\n",
    " 'y': 'cm',\n",
    " 'frame': 1,\n",
    " 'pumps': 'a.f.u.',\n",
    " 'signal_mean': 'a.f.u.',\n",
    "         'signal_max': 'a.f.u.',\n",
    " \"velocity\":\"um/s\",\n",
    " 'Istd': 'a.f.u.',\n",
    " 'Centerline': '1',\n",
    " 'Straightened': 1,\n",
    " 'area': 'px^2',\n",
    " 'temperature': 'C',\n",
    " 'humidity': '%',\n",
    " \"reversals_nose\":1,\n",
    " \"reversal_events_nose\":1,\n",
    " 'size': 'mm',\n",
    " 'age': 'h',\n",
    " '@acclimation': 'min',\n",
    "'Imean':'a.f.u'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e24aa-3552-42ec-b91c-6ce18f9da690",
   "metadata": {},
   "source": [
    "## Define path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f4e81-ede1-4e22-aad5-474034c74aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/gpfs/soma_fs/home/ramahefarivo/nif/Euphrasie2/test_script/Predationresults/'\n",
    "outpath = '/gpfs/soma_fs/home/ramahefarivo/nif/Euphrasie2/test_script/Predationresults/'\n",
    "\n",
    "# here are raw tracking coordinate files\n",
    "raw_data_path = '/gpfs/soma_fs/home/ramahefarivo/nif9201/1_rawdata_tracking/Projects/Macroscope_paper/Ppa_XE1995_Predatory_assay/Bite'\n",
    "folders = ['ER_Predation_61']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db40c2d9-ed37-4319-a3fe-524900efc17a",
   "metadata": {},
   "source": [
    "## pga.Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdbf6ef-d1b7-42be-8adf-95411c46c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the experiment\n",
    "control = pga.Experiment(strain='Ppa', condition='On larvae', scale=1.58, fps=30)\n",
    "control.load_data('/', units=units)  \n",
    "\n",
    "for fidx, folder in enumerate(folders[0:1]):\n",
    "    fpath = Path(raw_data_path) / Path(folder)\n",
    "    print(f\"Processing folder: {fpath}\")\n",
    "\n",
    "    # Get all .txt coordinate files in the folder\n",
    "    coords = list(filter(Path.is_file, fpath.glob('*.txt')))\n",
    "    print(f\"Found coordinate files: {coords}\")\n",
    "\n",
    "    if not coords:\n",
    "        raise FileNotFoundError(f\"No coordinate files found in {fpath}\")\n",
    "\n",
    "    # Read the coordinate file with new .txt version\n",
    "    tracks_path = coords[-1]  \n",
    "    try:\n",
    "        tracks = pd.read_csv(\n",
    "            tracks_path,\n",
    "            delim_whitespace=True,\n",
    "            skiprows=28,  \n",
    "            comment='#',  \n",
    "            names=[\"Frame\", \"Time\", \"X\", \"Y\", \"Z\"],  \n",
    "            engine=\"python\"\n",
    "        )\n",
    "        print(f\"Successfully read tracks from {tracks_path}. Shape: {tracks.shape}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading coordinate file {tracks_path}: {e}\")\n",
    "\n",
    "    # Load additional data (e.g., signals)\n",
    "    signals_path = f\"{path}{folder}_signals.json\"\n",
    "    print(f\"Loading signals from: {signals_path}\")\n",
    "    data = pd.read_json(signals_path, orient='split')\n",
    "    data.drop(['Straightened', 'StraightKymo', 'mask'], axis=1, errors='ignore')\n",
    "\n",
    "    print(f\"Max frame in signals data: {data['frame'].max()}\")\n",
    "\n",
    "    # Interpolate missing frames in signal data\n",
    "    old_frames = data['frame'].copy().values\n",
    "    idx = pd.Index(np.arange(data['frame'].min(), data['frame'].max() + 1), name=\"frame\")\n",
    "    data = data.set_index(\"frame\").reindex(idx).reset_index()\n",
    "    data = data.interpolate()\n",
    "\n",
    "    # Load and process centerline data\n",
    "    centerline_path = f\"{path}{folder}_um_centerlines.csv\"\n",
    "    centerline = pd.read_csv(centerline_path, header=None).to_numpy()\n",
    "    \n",
    "    # Reshape centerline from 2D to 3D (frames x points x coordinates)\n",
    "    centerline = np.reshape(centerline, (centerline.shape[0], centerline.shape[1] // 2, 2))\n",
    "    \n",
    "    # Scale track coordinates to micrometers (if needed)\n",
    "    tracks[\"X\"] *= 1000  # Convert to Âµm\n",
    "    tracks[\"Y\"] *= 1000\n",
    "\n",
    "    # Interpolate missing frames in track coordinates\n",
    "    idx = pd.Index(np.arange(tracks[\"Frame\"].min(), tracks[\"Frame\"].max() + 1), name=\"Frame\")\n",
    "    tracks = tracks.set_index(\"Frame\").reindex(idx).reset_index()\n",
    "    tracks = tracks.interpolate()\n",
    "\n",
    "    # Merge track and signal data into a single DataFrame\n",
    "    tracks = pd.merge(tracks, data, left_index=True, right_index=True)\n",
    "\n",
    "    # Ensure centerline and track lengths match by interpolating centerline\n",
    "    df_x = pd.DataFrame(centerline[:, :, 0], index=old_frames)\n",
    "    df_x = df_x.reindex(np.arange(np.min(old_frames), np.max(old_frames) + 1))\n",
    "    df_x.interpolate(method='linear', inplace=True)\n",
    "\n",
    "    df_y = pd.DataFrame(centerline[:, :, 1], index=old_frames)\n",
    "    df_y = df_y.reindex(np.arange(np.min(old_frames), np.max(old_frames) + 1))\n",
    "    df_y.interpolate(method='linear', inplace=True)\n",
    "\n",
    "    centerline = np.stack([df_x.values, df_y.values], axis=2)\n",
    "\n",
    "    # Rotate centerlines using matrix from coordinate file\n",
    "    matrix = None\n",
    "    with open(tracks_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        for idx, line in enumerate(lines):\n",
    "            if line.startswith('imageToStage'):\n",
    "                print(f\"Line {idx + 1} containing 'imageToStage': {line.strip()}\")\n",
    "                match = re.match(r'imageToStage\\s+([\\d\\.,\\-eE]+)', line.strip())\n",
    "                if not match:\n",
    "                    raise ValueError(f\"Failed to extract matrix from line: {line.strip()}\")\n",
    "\n",
    "                matrix_values = match.group(1).split(',')\n",
    "                if len(matrix_values) != 4:\n",
    "                    raise ValueError(f\"Expected 4 matrix values, but got {len(matrix_values)}: {matrix_values}\")\n",
    "\n",
    "                matrix = np.array(matrix_values, dtype=float).reshape(2, 2)\n",
    "                print(f\"Reformatted matrix as numpy array:\\n{matrix}\")\n",
    "                break\n",
    "\n",
    "        if matrix is None:\n",
    "            raise ValueError(\"imageToStage matrix not found in the file.\")\n",
    "\n",
    "    print(f\"Centerline shape before applying rotation: {centerline.shape}\")\n",
    "    print(f\"Rotation matrix extracted: \\n{matrix}\")\n",
    "    print(f\"Centerline shape is now {len(centerline)} and tracks length is {len(tracks)}.\")\n",
    "\n",
    "    # Rename columns for consistency\n",
    "    names = {\"Frame\": \"frame\", \"X\": \"x\", \"Y\": \"y\", \"Z\": \"z\"}\n",
    "    tracks.rename(columns=names, inplace=True)\n",
    "\n",
    "    # Add processed data to pga.Worm object and append to control.samples\n",
    "    w = pga.Worm(\n",
    "        '',\n",
    "        columns=None,\n",
    "        fps=control.fps,\n",
    "        scale=control.scale,\n",
    "        units=units,\n",
    "        particle_index=fidx,\n",
    "        load=False\n",
    "    )\n",
    "    \n",
    "    w.data = tracks.reset_index()\n",
    "    \n",
    "    # Remove duplicate columns if any exist\n",
    "    w.data = w.data.loc[:, ~w.data.columns.duplicated()].copy()\n",
    "    \n",
    "    w.centerline = centerline\n",
    "    control.samples.append(w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a045de-4221-415a-b890-5d99c48098ef",
   "metadata": {},
   "source": [
    "## Calculate and add 'negskew' and negskew_clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3a71a-91db-4b25-82c5-4ccce8b22fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_negskew_column(samples): # negskew from data directly after ini macro_analysis.py script\n",
    "    for w in samples:\n",
    "        try:\n",
    "            # Add 'negskew' column to worm's data\n",
    "            w.add_column(key='negskew', values=-1 * w.data['skew'], overwrite=True)\n",
    "            \n",
    "            # Verify if the new column is added\n",
    "            df = w.data\n",
    "            print(\"df columns after adding negskew:\", df.columns)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing worm {w}: {e}\")\n",
    "\n",
    "\n",
    "add_negskew_column(control.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc97e12-acc5-4877-836d-bb077189dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_signal_and_detect_peaks(samples):\n",
    "    for w in samples:\n",
    "        try:\n",
    "            # Access raw negskew signal directly\n",
    "            signal = w.data['negskew']\n",
    "            \n",
    "            # Keep the background subtraction but remove the smoothing\n",
    "            window_size = 30  # For background estimation only\n",
    "            bg_smooth = signal.rolling(window_size, min_periods=1, center=True).mean()\n",
    "            signal_clean = signal - bg_smooth\n",
    "\n",
    "            # Add the cleaned (non-smoothed) signal to data\n",
    "            signal_clean_reset = signal_clean.reset_index(drop=True)\n",
    "            w.add_column(key='negskew_clean', values=signal_clean_reset, overwrite=True)\n",
    "\n",
    "            # Detect peaks on the non-smoothed clean signal\n",
    "            peaks, properties = find_peaks(\n",
    "                signal_clean,\n",
    "                distance=4,          # Minimum peak separation\n",
    "                prominence=0.1,     # Minimum peak prominence\n",
    "                width=2             # Minimum peak width\n",
    "            )\n",
    "            print(f\"Number of peaks detected for worm {w}: {len(peaks)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing worm {w}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcedae-3a19-4272-911a-58f5acd91ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(samples):\n",
    "    for w in samples:\n",
    "        df = w.data\n",
    "        signal = df['negskew']\n",
    "        signal_clean = df['negskew_clean']\n",
    "        peaks, _ = find_peaks(\n",
    "            signal_clean, \n",
    "            distance=4, \n",
    "            prominence=0.1\n",
    "        )\n",
    "        \n",
    "        f, ax = plt.subplots(2, 1, figsize=(12, 8))\n",
    "        ax[0].plot(signal, label='Original negskew')\n",
    "        ax[0].plot(signal_clean, label='Cleaned (no smoothing, bg removed)')\n",
    "        ax[0].scatter(peaks, signal_clean[peaks], marker='+', color='red', label='Peaks')\n",
    "        ax[0].legend()\n",
    "        \n",
    "        ax[1].plot(signal_clean, label='Cleaned signal')\n",
    "        ax[1].scatter(peaks, signal_clean[peaks], marker='+', color='red', label='Peaks')\n",
    "        ax[1].legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# Call the updated functions\n",
    "smooth_signal_and_detect_peaks(control.samples)\n",
    "plot_results(control.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db1c69-2490-498e-883f-0fd3773f5c16",
   "metadata": {},
   "source": [
    "## Calculate properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd219f1-f898-49ef-8644-600e2a23d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate extra stuff\n",
    "ppars = {'sensitivity' : 0.99, 'min_distance' : 4, 'adaptive_window':300, 'min_prominence':0.05}\n",
    "\n",
    "control.calculate_property('time')\n",
    "control.calculate_property('locations')\n",
    "control.calculate_property('velocity', dt=30)\n",
    "control.calculate_property('smoothed', key='velocity', window=300, aligned = False)\n",
    "control.calculate_property(\"reversals_nose\",dt =10, angle_threshold = 140, w_smooth = 30, min_duration = 30)\n",
    "control.calculate_property(\"reversals\", angle_threshold=100, animal_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970edf92-6959-431b-aed3-e2f530dfdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "control.units['negskew'] = 'a.f.u.'  \n",
    "pumpkey = 'negskew'\n",
    "\n",
    "# Parameters for feature extraction\n",
    "ppars = {\n",
    "    'sensitivity': 0.99,\n",
    "    'min_distance': 4,\n",
    "    'adaptive_window': 300,\n",
    "    'min_prominence': 0.05,\n",
    "    'use_pyampd': True\n",
    "}\n",
    "\n",
    "# Preprocess the negskew signal\n",
    "control.calculate_property(\"preprocess_signal\", key=pumpkey, w_outlier=None, w_bg=30, w_smooth=1)\n",
    "\n",
    "# Detect pumps using the cleaned negskew signal\n",
    "control.calculate_property(\"pumps\", key=f'{pumpkey}_clean', **ppars)\n",
    "\n",
    "# Calculate count rate (e.g., pump events per unit time)\n",
    "control.calculate_property(\"count_rate\", window=30, min_periods=30)\n",
    "\n",
    "# Smooth the count rate to reduce noise\n",
    "control.calculate_property(\"smoothed\", key=\"count_rate_pump_events\", window=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0cd57-ab97-4e02-9d1e-0b5a8a3c8344",
   "metadata": {},
   "source": [
    "## Plots exemples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27c75b-5e09-4416-bf14-5f06087da4bf",
   "metadata": {},
   "source": [
    "### Reversals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc9509-c52d-4f02-ac2e-1c6057c96176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the single recording\n",
    "ex = control[:1]  \n",
    "\n",
    "# Time offset for plotting (e.g., start at 5 minutes)\n",
    "offset = 5 * 30 * 60  # 5 minutes in frames (30 fps)\n",
    "\n",
    "reversals = ex.get_sample_metric('reversals_nose')\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.set_aspect(1)\n",
    "plot, x1, y1 = ex.plot(ax, ('x_scaled', 'y_scaled'), metric=None, color='navy', label='', zorder=-5)\n",
    "x1_masked = np.ma.masked_where(reversals.values == 0, x1)\n",
    "y1_masked = np.ma.masked_where(reversals.values == 0, y1)\n",
    "ax.plot(x1, y1, color='navy', label='Full Trajectory')\n",
    "ax.plot(x1_masked, y1_masked, color='red', label='Reversals')\n",
    "\n",
    "xmax = ax.get_xlim()[1]\n",
    "ymin = ax.get_ylim()[0]\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel(\"X (um)\")\n",
    "ax.set_ylabel(\"Y (um)\")\n",
    "ax.legend()\n",
    "\n",
    "# Adjust layout and display plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de2e07-841c-4f95-add7-2f08c49b1cde",
   "metadata": {},
   "source": [
    "### Velocity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8534e7c3-09b6-49fc-90b1-40a36dd33cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = control\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,8))\n",
    "axes = axes.ravel()\n",
    "vmax = 200\n",
    "n = 30*5\n",
    "for loc, worm in enumerate(control.samples[:20]):\n",
    "    axes[loc].set_title(worm.experiment, fontsize=8)\n",
    "    style.multicolor(axes[loc],worm.data.x[::30]/1000, worm.data.y[::30]/1000,None,t=worm.data.velocity[::30], c=plt.cm.viridis, \n",
    "                     threedim = False, etho = False, cg = 1, vmin = 0, vmax = vmax)\n",
    "    axes[loc].set_aspect(1)\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, norm=plt.Normalize(vmin=0, vmax=vmax))\n",
    "plt.colorbar(ax = axes,mappable = sm, label = 'velocity (um/s)', fraction =0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327cbd1-5c58-472c-b1ae-85de72d05320",
   "metadata": {},
   "source": [
    "### Density plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0e290-772a-4099-bb1d-e0a99c893305",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1, figsize=(2.5,2.5))\n",
    "loc = 0\n",
    "axes = [axes]\n",
    "vmax = 0.015\n",
    "cm = plt.cm.viridis\n",
    "\n",
    "\n",
    "x = control.get_sample_metric('velocity_smoothed', metric = 'collapse', axis=0)\n",
    "y = control.get_sample_metric('rate', metric = 'collapse', axis=0)\n",
    "tmp = pd.concat([x, y], axis=1)\n",
    "tmp = tmp.dropna()\n",
    "\n",
    "hb = axes[loc].hexbin(tmp.iloc[:,0], tmp.iloc[:,1], extent = [0,300,0,5], gridsize=30)\n",
    "hb = axes[loc].hexbin(tmp.iloc[:,0], tmp.iloc[:,1], C=np.ones(len(tmp), dtype=float)/hb.get_array().sum(), \n",
    "                      extent = [0,300,0,5], gridsize=30, cmap=cm, reduce_C_function=np.sum, vmax = vmax, vmin =0)\n",
    "print(hb.get_array()[20:-20].max(), hb.get_array().sum())\n",
    "\n",
    "ax = axes[-1]\n",
    "cax = fig.add_axes([ax.get_position().x1+0.02,ax.get_position().y0,0.02,ax.get_position().height])\n",
    "cbar = plt.colorbar(hb, cax=cax, ticks=[0,  vmax]) # Similar to fig.colorbar(im, cax = cax)\n",
    "\n",
    "plt.setp(axes[::2],  ylabel='pumping rate (Hz)');\n",
    "plt.setp(axes[-2:], xlabel='velocity (um/s)');\n",
    "plt.setp(axes,xlim=(0,300), ylim=(0,5), yticks=[0,1,2,3,4,5], xticks=[0,150,300]);\n",
    "#fig.colorbar(cbar, ticks=[0,  vmax])\n",
    "cbar.ax.set_yticklabels(['0',  f'> {vmax}'])  # vertically oriented colorbar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pumping2)",
   "language": "python",
   "name": "pumping2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
